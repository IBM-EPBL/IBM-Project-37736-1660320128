{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OPBj3QFBW6"
      },
      "source": [
        "# Colab Link: https://colab.research.google.com/drive/1SorydzFCssfgbJueqNoC6tSmKtasZqtT?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzSs7BiYE6XM"
      },
      "source": [
        "# Package installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9rjSc5EWi02k"
      },
      "outputs": [],
      "source": [
        "!pip install jupyter-dash\n",
        "!pip install dash\n",
        "!pip install pyngrok\n",
        "!pip install tensorflow\n",
        "!pip install sklearn\n",
        "!pip install jupyterlab-dash\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUsBhgWsE3RS"
      },
      "source": [
        "# Ngrok Authentication Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRqrqNsw3Mfj",
        "outputId": "fbb41618-7a02-42ba-cd16-7432b6a819ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2GuOWCWZbBbtulADXsAB8bjKGHC_5e53eZJ1ZUj7SwCQohFhA\n",
        "#!mkdir ~/.kaggle\n",
        "#!cp kaggle.json ~/.kaggle/\n",
        "#!kaggle datasets download -d paulsujan/sales-prediction\n",
        "#!unzip /content/sales-prediction.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufrwQjwbFRHx"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eUFDuSaeF5Be"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import base64\n",
        "import datetime\n",
        "import io\n",
        "from jupyter_dash import JupyterDash\n",
        "from dash import dcc, html, Dash, dash_table\n",
        "import dash_core_components as dcc\n",
        "from dash import html\n",
        "from dash.dependencies import Input, Output, State\n",
        "import pandas as pd\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import plotly.express as px\n",
        "import plotly\n",
        "from base64 import b64encode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMpQmSBRFUh4"
      },
      "source": [
        "# Clearing Exsisting Ngrok Sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUFvPdVeA0SI"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2gL8YfiFaK5"
      },
      "source": [
        "# Creating new Ngrok Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQPjcLrPA1cV"
      },
      "outputs": [],
      "source": [
        "#public_url = ngrok.connect(8050)\n",
        "#public_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id_FMEkLFgTQ"
      },
      "source": [
        "# Backend Code\n",
        "##Semi-Optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0Pi57auMijr9",
        "outputId": "7751a684-4398-49fb-e111-066fab1c5f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash app running on:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8050, \"/\", \"http://127.0.0.1:8050/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def backend_main(contents, filename, datee):\n",
        "  content_type, content_string = contents.split(',')\n",
        "\n",
        "  decoded = base64.b64decode(content_string)\n",
        "  try:\n",
        "      if 'csv' in filename:\n",
        "            # Assume that the user uploaded a CSV file\n",
        "          store_sales = pd.read_csv(\n",
        "              io.StringIO(decoded.decode('utf-8')))\n",
        "      elif 'xls' in filename:\n",
        "            # Assume that the user uploaded an excel file\n",
        "          store_sales = pd.read_excel(io.BytesIO(decoded))\n",
        "  except Exception as e:\n",
        "    return html.Div([\n",
        "            'There was an error processing this file.'\n",
        "        ])\n",
        "  #Variable Declaration\n",
        "  #store_sales = pd.read_csv(\"mock_kaggle.csv\")\n",
        "  date = 'data'\n",
        "  sales = 'venda'\n",
        "  sales_diff = 'sales_diff'\n",
        "  LP = 'venda'\n",
        "  img = 'Predict.jpg'\n",
        "  drpdata = ['estoque', 'preco']\n",
        "  pred = 'Prediction'\n",
        "  predtrue = 'Original'\n",
        "  predfalse = 'Prediction'\n",
        "  #Dropping store and item columns\n",
        "  store_sales = store_sales.drop(drpdata, axis=1)\n",
        "  #Coverting 'date' string to 'Date' type\n",
        "  store_sales[date] = pd.to_datetime(store_sales[date])\n",
        "  #Sumation of sales in months\n",
        "  store_sales[date] = store_sales[date].dt.to_period(\"M\")\n",
        "  monthly_sales = store_sales.groupby(date).sum().reset_index()\n",
        "  #Converting resulting 'date' type to 'timestamp' datatype\n",
        "  monthly_sales[date] = monthly_sales[date].dt.to_timestamp()\n",
        "  # Visualization\n",
        "  #plt.figure(figsize=(15,5))\n",
        "  #plt.plot(monthly_sales[date], monthly_sales[sales])\n",
        "  #plt.xlabel(\"Date\")\n",
        "  #plt.ylabel(\"Sales\")\n",
        "  #plt.title(\"RESULT\")\n",
        "  #plt.show()\n",
        "  # Finding Difference of sales month\n",
        "  monthly_sales[sales_diff] = monthly_sales[sales].diff()\n",
        "  monthly_sales = monthly_sales.dropna()\n",
        "  # Dropping 'sales' and 'date'\n",
        "  supervised_data = monthly_sales.drop([date, sales], axis=1)\n",
        "  # Preparing Supervised Data\n",
        "  for i in range(1,13):\n",
        "    col_name = 'month_' + str(i)\n",
        "    supervised_data[col_name] = supervised_data[sales_diff].shift(i)\n",
        "  supervised_data = supervised_data.dropna().reset_index(drop=True)\n",
        "  ## Split data into train and test\n",
        "  train_data = supervised_data[:-12]\n",
        "  test_data = supervised_data[-12:]\n",
        "  #print(\"Train Data Shape: \", train_data.shape)\n",
        "  #print(\"Test Data Shape: \", test_data.shape)\n",
        "  scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "  scaler.fit(train_data)\n",
        "  train_data = scaler.transform(train_data)\n",
        "  test_data = scaler.transform(test_data)\n",
        "  x_train, y_train = train_data[:,1:], train_data[:,0:1]\n",
        "  x_test, y_test = test_data[:,1:], test_data[:,0:1]\n",
        "  y_train = y_train.ravel()\n",
        "  y_test = y_test.ravel()\n",
        "  #print(\"X_train Shape: \", x_train.shape)\n",
        "  #print(\"Y_train Shape: \", y_train.shape)\n",
        "  #print(\"X_test Shape: \", x_test.shape)\n",
        "  #print(\"Y_test Shape: \", y_test.shape)\n",
        "  # Make Prediction data frame to merge the predicted sales of all trained algs\n",
        "  sales_dates = monthly_sales[date][-12:].reset_index(drop=True)\n",
        "  predict_df = pd.DataFrame(sales_dates)\n",
        "  act_sales = monthly_sales[sales][-13:].to_list()\n",
        "  #print(act_sales)\n",
        "  # To create the linear regression model, and predicted output\n",
        "  lr_model = LinearRegression()\n",
        "  lr_model.fit(x_train, y_train)\n",
        "  lr_pre = lr_model.predict(x_test)\n",
        "  lr_pre = lr_pre.reshape(-1,1)\n",
        "  ###This is a set matrix - contains the input features of the test data, and also the predicted data output\n",
        "  lr_pre_test_set = np.concatenate([lr_pre, x_test], axis=1)\n",
        "  lr_pre_test_set = scaler.inverse_transform(lr_pre_test_set)\n",
        "  result_list = []\n",
        "  for index in range(0, len(lr_pre_test_set)):\n",
        "    result_list.append(lr_pre_test_set[index][0] + act_sales[index])\n",
        "  lr_pre_series = pd.Series(result_list, name=LP)\n",
        "  predict_df = predict_df.merge(lr_pre_series, left_index=True, right_index=True)\n",
        "  for i in predict_df[date]:\n",
        "    predict_df[pred] = predtrue\n",
        "\n",
        "  for i in monthly_sales[date]:\n",
        "    monthly_sales[pred] = predfalse\n",
        "\n",
        "  ############ This part need to learn, i think ###############\n",
        "  lr_mse = np.sqrt(mean_squared_error(predict_df[LP], monthly_sales[sales][-12:]))\n",
        "  lr_mae = mean_absolute_error(predict_df[LP], monthly_sales[sales][-12:])\n",
        "  lr_r2 = r2_score = (predict_df[LP], monthly_sales[sales][-12:])\n",
        "  monthly_sales[sales] = monthly_sales[sales][:-12]\n",
        "  #print(\"Linear Regression MSE: \", lr_mse)\n",
        "  #print(\"Linear Regression MAE: \", lr_mae)\n",
        "  #print(\"Linear Regression R2: \", lr_r2)\n",
        "  #plt.figure(figsize=(15,5))\n",
        "  ###Actual Sales\n",
        "  #plt.plot(monthly_sales[date], monthly_sales[sales])\n",
        "  ###Predicted Sales\n",
        "  #plt.plot(predict_df[date], predict_df[LP])\n",
        "  #plt.xlabel(\"Date\")\n",
        "  #plt.ylabel(\"Sales\")\n",
        "  #plt.legend(['Actual sales', 'Predicted Sales'])\n",
        "  #plt.savefig(img)\n",
        "  result = pd.concat([monthly_sales.drop(sales_diff, axis=1),predict_df]).dropna()## find solution\n",
        "  fig = px.scatter(result, x=date, y=sales, color=pred, trendline=\"lowess\", trendline_options=dict(frac=0.1))\n",
        "  fig.show()\n",
        "  plotly.offline.plot(fig, filename='Predict.html')\n",
        "  return html.Div([\n",
        "      html.Button(\"Download Graph\", id=\"btn_image\"),\n",
        "      dcc.Download(id=\"download-image\")\n",
        "    ])\n",
        "\n",
        "app = JupyterDash(__name__)\n",
        "app.title =\"Retail Store Stock Inventory Analysis\"\n",
        "app.layout = html.Div(children=[\n",
        "    html.H1(children='Retail Stock Management'),\n",
        "    html.Div(id='output-sign-in', children=[\n",
        "        html.H2(children='Username'),\n",
        "        dcc.Input(\n",
        "          id=\"Username\",\n",
        "          type=\"text\",\n",
        "          placeholder=\"Username\",\n",
        "          ),\n",
        "        html.Br(),\n",
        "        html.H2(children=\"Password\"),\n",
        "        dcc.Input(\n",
        "              id=\"Password\",\n",
        "              type=\"password\",\n",
        "              placeholder=\"Password\",\n",
        "          ),\n",
        "        html.Br(),\n",
        "        html.Br(),\n",
        "        html.Br(),\n",
        "        html.Button(\"Login\", id=\"btn_login\"),\n",
        "      ]),\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"output-sign-in\", \"children\"),\n",
        "    Input('btn_login', 'n_clicks'),\n",
        "    [State('Username', 'value'), State('Password', 'value')],\n",
        "    prevent_initial_call=True,)\n",
        "def func(n_clicks, Username, Password):\n",
        "    if Username == 'Admin' and Password == 'Admin':\n",
        "        children = [\n",
        "          html.Div(id='content', children=[\n",
        "          html.Button(\"Cognos\", id=\"cognos\"),\n",
        "          dcc.Upload(\n",
        "            id='upload-data',\n",
        "            children=html.Div([\n",
        "                'Drag and Drop or ',\n",
        "                html.A('Select Files')\n",
        "            ]),\n",
        "            style={\n",
        "                'width': '100%',\n",
        "                'height': '60px',\n",
        "                'lineHeight': '60px',\n",
        "                'borderWidth': '1px',\n",
        "                'borderStyle': 'dashed',\n",
        "                'borderRadius': '5px',\n",
        "                'textAlign': 'center',\n",
        "                'margin': '10px'\n",
        "            },\n",
        "            # Allow multiple files to be uploaded\n",
        "            multiple=True\n",
        "          ),\n",
        "          html.Div(id='output-data-upload'),])\n",
        "          ]\n",
        "        return children\n",
        "    else:\n",
        "      return html.Div(children=[\n",
        "          html.H2(children='Username'),\n",
        "          dcc.Input(\n",
        "            id=\"Username\",\n",
        "            type=\"text\",\n",
        "            placeholder=\"Username\",\n",
        "            ),\n",
        "          html.Br(),\n",
        "          html.H2(children=\"Password\"),\n",
        "          dcc.Input(\n",
        "                id=\"Password\",\n",
        "                type=\"password\",\n",
        "                placeholder=\"Password\",\n",
        "            ),\n",
        "          html.Br(),\n",
        "          html.Br(),\n",
        "          html.Br(),\n",
        "          html.Button(\"Login\", id=\"btn_login\"),\n",
        "          html.H1(\"Username or Password is Invalid\"),\n",
        "          ])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"content\", \"children\"),\n",
        "    Input(\"cognos\", \"n_clicks\"),\n",
        "    prevent_initial_call=True,\n",
        ")\n",
        "def func(n_clicks):\n",
        "    children = [\n",
        "                  html.Iframe(src=\"https://us3.ca.analytics.ibm.com/bi/?perspective=dashboard&pathRef=.my_folders%2FFinal%2BDashboard&action=view&mode=dashboard&subView=model00000184844f532c_00000004\",\n",
        "                  style={\"height\": \"1067px\", \"width\": \"100%\"}\n",
        "          )]\n",
        "    return children\n",
        "\n",
        "@app.callback(Output('output-data-upload', 'children'),\n",
        "              Input('upload-data', 'contents'),\n",
        "              [State('upload-data', 'filename'), State('upload-data', 'last_modified')],\n",
        "              prevent_initial_call=True,)\n",
        "def update_output( list_of_contents, list_of_names, list_of_dates ):\n",
        "  if list_of_contents is not None:\n",
        "        children = [\n",
        "            backend_main(c, n, d) for c, n, d in\n",
        "            zip(list_of_contents, list_of_names, list_of_dates)]\n",
        "        return children\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"download-image\", \"data\"),\n",
        "    Input(\"btn_image\", \"n_clicks\"),\n",
        "    prevent_initial_call=True,\n",
        ")\n",
        "def func(n_clicks):\n",
        "    return dcc.send_file(\n",
        "        \"Predict.html\"\n",
        "    )\n",
        "\n",
        "app.run_server(mode='external', use_reloader=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}